{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd7d5be0",
   "metadata": {},
   "source": [
    "# PPO Trading Agent — Training & Evaluation\n",
    "\n",
    "Train a custom PPO agent on 20 S&P 500 stocks, visualize learning curves, and evaluate on held-out test data."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import sys, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "# Ensure local packages are importable\n",
    "sys.path.insert(0, os.path.abspath('.'))\n",
    "\n",
    "from src.data_loader import process_data_with_indicators, split_data\n",
    "from envs.naive_env import TradingEnvGuided\n",
    "from agent.ppo import PPO"
   ],
   "id": "b8c868e815893fc1",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ce0df8e0",
   "metadata": {},
   "source": [
    "## 1. Load & Process Data"
   ]
  },
  {
   "cell_type": "code",
   "id": "86fcd34b",
   "metadata": {},
   "source": [
    "tickers = [\n",
    "    'AAPL', 'MSFT', 'GOOGL', 'AMZN', 'NVDA',\n",
    "    'META', 'TSLA', 'NFLX', 'UNH', 'JNJ',\n",
    "    'V', 'JPM', 'WMT', 'MA', 'PG',\n",
    "    'HD', 'DIS', 'BAC', 'XOM', 'CVX'\n",
    "]\n",
    "\n",
    "# Load from local CSVs (already downloaded via load_data.ipynb)\n",
    "stock_data = {}\n",
    "for ticker in tickers:\n",
    "    df = pd.read_csv(f'data/{ticker}.csv', skiprows=2, index_col='Date', parse_dates=True)\n",
    "    df.columns = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
    "    stock_data[ticker] = df\n",
    "\n",
    "# Add technical indicators\n",
    "stock_data = process_data_with_indicators(stock_data)\n",
    "\n",
    "# Split: train (2009-2019), val (2020), test (2021-2025)\n",
    "# Your choice of split, feel free to change in src/data_loader.py\n",
    "training_data, validation_data, test_data = split_data(stock_data)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "71fad9ab",
   "metadata": {},
   "source": [
    "## 2. Train PPO Agent"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create training environment\n",
    "train_env = TradingEnvGuided(training_data)\n",
    "print(f\"Observation space: {train_env.observation_space.shape}\")\n",
    "print(f\"Action space:      {train_env.action_space.shape}\")\n",
    "print(f\"Max steps:         {train_env.max_steps}\")\n",
    "\n",
    "# Initialize PPO\n",
    "ppo = PPO(\n",
    "    env=train_env,\n",
    "    lr=3e-4,\n",
    "    gamma=0.99,\n",
    "    gae_lambda=0.95,\n",
    "    clip_range=0.2,\n",
    "    n_epochs=10,\n",
    "    batch_size=64,\n",
    "    ent_coef=0.01,\n",
    "    vf_coef=0.5,\n",
    ")\n",
    "\n",
    "# Train\n",
    "N_ITERATIONS = 10\n",
    "STEPS_PER_ITER = 2048\n",
    "training_stats = ppo.train(n_iterations=N_ITERATIONS, steps_per_iter=STEPS_PER_ITER)"
   ],
   "id": "77632b2017ab9157",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(training_stats)",
   "id": "9673df3197156df0",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9e7011d1",
   "metadata": {},
   "source": [
    "## 3. Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "id": "0aec4b8a",
   "metadata": {},
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 8))\n",
    "fig.suptitle('PPO Training Curves', fontsize=16, fontweight='bold')\n",
    "\n",
    "iters = training_stats['iterations']\n",
    "\n",
    "# Mean Reward\n",
    "ax = axes[0, 0]\n",
    "ax.plot(iters, training_stats['mean_rewards'], color='#2196F3')\n",
    "ax.set_ylabel('Mean Reward')\n",
    "ax.set_title('Reward per Iteration')\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "# Policy Loss\n",
    "ax = axes[0, 1]\n",
    "ax.plot(iters, training_stats['policy_losses'], color='#F44336')\n",
    "ax.set_ylabel('Policy Loss')\n",
    "ax.set_title('Policy Loss')\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "# Value Loss\n",
    "ax = axes[1, 0]\n",
    "ax.plot(iters, training_stats['value_losses'], color='#4CAF50')\n",
    "ax.set_ylabel('Value Loss')\n",
    "ax.set_xlabel('Iteration')\n",
    "ax.set_title('Value Loss')\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "# Entropy\n",
    "ax = axes[1, 1]\n",
    "ax.plot(iters, training_stats['entropies'], color='#FF9800')\n",
    "ax.set_ylabel('Entropy')\n",
    "ax.set_xlabel('Iteration')\n",
    "ax.set_title('Entropy (exploration)')\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d71857e9",
   "metadata": {},
   "source": [
    "## 4. Evaluate on Test Data"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def evaluate_agent(ppo_agent, stock_data, label='Test'):\n",
    "    \"\"\"Run PPO on an environment and track net worth over time.\"\"\"\n",
    "    env = TradingEnvGuided(stock_data)\n",
    "    state, _ = env.reset()\n",
    "    \n",
    "    net_worths = [env.initial_balance]\n",
    "    balances = [env.balance]\n",
    "    steps = [0]\n",
    "    \n",
    "    for step in range(env.max_steps):\n",
    "        action = ppo_agent.predict(state)\n",
    "        state, reward, done, truncated, _ = env.step(action)\n",
    "        \n",
    "        net_worths.append(env.net_worth)\n",
    "        balances.append(env.balance)\n",
    "        steps.append(step + 1)\n",
    "        \n",
    "        if done or truncated:\n",
    "            break\n",
    "    \n",
    "    # Get dates from one of the tickers\n",
    "    sample_ticker = list(stock_data.keys())[0]\n",
    "    dates = stock_data[sample_ticker].index[:len(net_worths)]\n",
    "    \n",
    "    total_return = (net_worths[-1] - net_worths[0]) / net_worths[0] * 100\n",
    "    returns = np.diff(net_worths) / np.array(net_worths[:-1])\n",
    "    sharpe = np.mean(returns) / (np.std(returns) + 1e-8) * np.sqrt(252)\n",
    "    \n",
    "    peak = np.maximum.accumulate(net_worths)\n",
    "    max_dd = np.max((peak - net_worths) / peak) * 100\n",
    "    \n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"{label} Results ({len(net_worths)-1} steps)\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"Final Net Worth:  ${net_worths[-1]:,.2f}\")\n",
    "    print(f\"Total Return:     {total_return:+.2f}%\")\n",
    "    print(f\"Sharpe Ratio:     {sharpe:.3f}\")\n",
    "    print(f\"Max Drawdown:     {max_dd:.2f}%\")\n",
    "    \n",
    "    return {'net_worths': net_worths, 'dates': dates, 'returns': returns,\n",
    "            'total_return': total_return, 'sharpe': sharpe, 'max_dd': max_dd}\n",
    "\n",
    "# Evaluate on validation and test sets\n",
    "val_results = evaluate_agent(ppo, validation_data, label='Validation')\n",
    "test_results = evaluate_agent(ppo, test_data, label='Test')"
   ],
   "id": "6d2356f725f5013e",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2d4b4d81",
   "metadata": {},
   "source": [
    "## 5. Net Worth Over Time"
   ]
  },
  {
   "cell_type": "code",
   "id": "1000e132",
   "metadata": {},
   "source": [
    "import matplotlib.dates as mdates\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "initial = 100000\n",
    "\n",
    "for ax, res, title in [(axes[0], val_results, 'Validation (2020)'),\n",
    "                        (axes[1], test_results, 'Test (2021-2025)')]:\n",
    "    dates = res['dates']\n",
    "    nw = np.array(res['net_worths'][:len(dates)])\n",
    "    \n",
    "    ax.plot(dates, nw, color='#1565C0', linewidth=1.5, label='PPO Net Worth')\n",
    "    ax.axhline(initial, color='gray', linestyle='--', alpha=0.6, label=f'Initial ${initial:,}')\n",
    "    ax.fill_between(dates, initial, nw, where=nw >= initial, alpha=0.15, color='green')\n",
    "    ax.fill_between(dates, initial, nw, where=nw < initial, alpha=0.15, color='red')\n",
    "    \n",
    "    ax.set_title(f'{title}\\nReturn: {res[\"total_return\"]:+.1f}%  |  Sharpe: {res[\"sharpe\"]:.2f}  |  MaxDD: {res[\"max_dd\"]:.1f}%',\n",
    "                 fontsize=11)\n",
    "    ax.set_ylabel('Net Worth ($)')\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
    "    plt.setp(ax.xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
    "    ax.legend(loc='upper left', fontsize=9)\n",
    "    ax.grid(alpha=0.3)\n",
    "\n",
    "plt.suptitle('PPO Agent — Portfolio Performance', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e453dd34",
   "metadata": {},
   "source": [
    "## 6. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "id": "f855851c",
   "metadata": {},
   "source": [
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "save_path = 'models/ppo_trading.pt'\n",
    "torch.save({\n",
    "    'policy_state_dict': ppo.policy.state_dict(),\n",
    "    'optimizer_state_dict': ppo.optimizer.state_dict(),\n",
    "    'training_stats': training_stats,\n",
    "    'obs_shape': train_env.observation_space.shape[0],\n",
    "    'action_shape': train_env.action_space.shape[0],\n",
    "}, save_path)"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
